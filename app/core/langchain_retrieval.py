from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

from models.chat_history_model import ChatHistory
from .base import chat_llm, chroma_vector_store


def build_history_template(chat_history_list: list[ChatHistory]):
    """构建聊天历史模板"""

    if type(chat_history_list) != list or len(chat_history_list) == 0:
        return []

    history_messages: list[BaseMessage] = []
    # 历史记录转换为 LangChain 消息对象数组
    for history in chat_history_list:
        if history.role == "user":
            history_messages.append(HumanMessage(content=history.content))
        elif history.role == "assistant":
            history_messages.append(AIMessage(content=history.content))
    return history_messages


# 构建问答链


def build_qa_chain():

    # 初始化 Chroma 向量数据库
    vector_store = chroma_vector_store()

    # 初始化 deepseek 模型
    llm = chat_llm()

    # 初始化检索，并配置
    # 使用mmr的检索算法，
    retriever = vector_store.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 3,  # 检索结果返回最相似的文档数量
            "fetch_k": 20,  # 要传递给 MMR 算法的文档量
            "lambda_mult": 0.5,  # MMR 返回的结果多样性，1 表示最小多样性，0 表示最大值。（默认值：0.5）
        },
    )

    # system 提示词模板
    # system_template = """
    #     您是超级牛逼哄哄的小天才助手，专注于文档知识的问答，是一个设计用于査询文档来回答问题的代理。
    #     如果有人提问等关于您的名字的问题，您就回答：“我是超级牛逼哄哄的小天才助手，专注于文档知识的问答。”作为答案。
    #     您可以使用文档检索工具，并基于检索内容来回答问题。您可能不查询文档就知道答案，但是您仍然应该查询文档来获得答案。
    #     你服务于专业技术人员，根据文档内容回答尽可能详细，可以使用专业术语来回答问题，要让提问者感觉这是你本身了解的知识。
    #     如果您从文档中找不到任何信息用于回答问题，则只需返回“抱歉，这个问题我还不知道。”作为答案，不可以自由发挥，不可以胡编乱造。
    #     文档内容：{context}
    #     """
    # 电影问答
    system_template = """
    你是一位专业的电影和剧集信息问答助手，具备强大的知识检索与理解能力，能够帮助用户准确、高效地查询电影与电视剧的各种信息。

    你可以基于提供的文档或检索内容，回答以下类型的问题：
    - 查询某部电影或剧集的演职员信息（导演、演员、编剧等）
    - 概括剧情简介或核心看点
    - 提供观众评分与评论摘要
    - 推荐与某部作品相似的其他作品
    - 根据类型（如科幻、爱情、悬疑等）或上映年代筛选作品

    你始终依赖检索到的文档内容进行回答，不可凭空编造。同时，需要读取文档中所有有关的信息。当文档中没有足够信息支撑回答时，你应回复：“抱歉，暂时没有相关信息。”

    你服务于希望获取影视信息的普通用户，回答应通俗易懂、条理清晰，如有需要可适当使用行业术语，但需简洁解释。

    检索结果内容如下：
    {context}
    """
    prompt = ChatPromptTemplate(
        [
            ("system", system_template),
            MessagesPlaceholder("chat_history"),
            ("human", "{question}"),
        ]
    )

    # 构建检索链管道 Runnable
    # retriever.invoke() 作用是根据用户问题检索匹配最相关的文档
    # x 值是管道里的参数，包括 question，chat_history，还要其他有关langchain的参数
    # 输入（字典） → 检索文档（context） → 构建 prompt → 输入给 LLM → 输出文本结果
    return (
        {
            "context": lambda x: retriever.invoke(x["question"]),
            "chat_history": lambda x: x["chat_history"],
            "question": lambda x: x["question"],
        }
        | prompt
        | llm
        | StrOutputParser()
    )
